# Gradient Descent from Scratch

This project implements Gradient Descent from scratch in Python, including core components like the cost function, parameter updates, and visualization. It serves as an educational resource for understanding the internal workings of optimization algorithms without relying on external machine learning libraries.

Features-

    ✅ Gradient Descent implementation from scratch (no scikit-learn or TensorFlow)

    ✅ Support for Linear Regression

    ✅ Customizable learning rate and number of iterations

    ✅ Cost function (Mean Squared Error) computation

    ✅ Real-time visualization of cost function convergence

    ✅ Simple and easy-to-read code
